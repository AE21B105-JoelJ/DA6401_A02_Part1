{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5675fe9",
   "metadata": {},
   "source": [
    "This notebook is meant for doing things which are necessary for report point of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79095dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the prediction images from the test folder\n",
    "# Importing the necessary libraries #\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as F\n",
    "import lightning as L\n",
    "from typing import List\n",
    "from lightning.pytorch import Trainer\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import precision_score\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11459929",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68c8c845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mae21b105\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "wandb.login()\n",
    "# Initializing wandb logger #\n",
    "wandb_logger = WandbLogger(\n",
    "    entity=\"A2_DA6401_DL\",\n",
    "    project=\"Lightning_CNN\",       \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caf56a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/joel/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"5ef7c4bbfa350a2ffd3c198cb9289f544e3a0910\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e0d7e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to give the activation function #\n",
    "def return_activation_function(activation : str = \"ReLU\"):\n",
    "    possible_activations = [\"ReLU\", \"Mish\", \"GELU\", \"SELU\", \"SiLU\", \"LeakyReLU\" ]\n",
    "    # Assertion to be made for the activations possible #\n",
    "    assert activation in possible_activations, f\"activation not in {possible_activations}\"\n",
    "\n",
    "    if activation == \"ReLU\":\n",
    "        return nn.ReLU()\n",
    "    elif activation == \"GELU\":\n",
    "        return nn.GELU()\n",
    "    elif activation == \"SiLU\":\n",
    "        return nn.SiLU()\n",
    "    elif activation == \"SELU\":\n",
    "        return nn.SELU()\n",
    "    elif activation == \"Mish\":\n",
    "        return nn.Mish()\n",
    "    else:\n",
    "        return nn.LeakyReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbfd4d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_(nn.Module):\n",
    "    def __init__(self, config = None):\n",
    "        super().__init__()\n",
    "        # Configuration to build the CNN #\n",
    "        self.config = config\n",
    "        \n",
    "        # Some assertions to be made #\n",
    "        assert config[\"no_of_conv_blocks\"]==len(config[\"no_of_filters\"]), \"The filter number do not match with number of conv layers\"\n",
    "        assert config[\"no_of_conv_blocks\"]==len(config[\"filter_sizes\"]), \"The filter sizes do not match with number of conv layers\"\n",
    "        assert config[\"no_of_conv_blocks\"]==len(config[\"conv_strides\"]), \"The strides do not match with number of conv layers\"\n",
    "        assert config[\"no_of_conv_blocks\"]==len(config[\"conv_padding\"]), \"The padding do not match with number of conv layers\"\n",
    "        assert config[\"no_of_conv_blocks\"]==len(config[\"max_pooling_stride\"]), \"The max pooling stride do not match with number of conv layers\"\n",
    "\n",
    "        # building the convolution blocks #\n",
    "        conv_blocks = []\n",
    "        for block_no in range(config[\"no_of_conv_blocks\"]):\n",
    "            # Getting the hyper-parameters from the config #\n",
    "            if block_no == 0:\n",
    "                in_channels = config[\"input_channels\"]\n",
    "            else:\n",
    "                in_channels = config[\"no_of_filters\"][block_no-1]\n",
    "            out_channels = config[\"no_of_filters\"][block_no]\n",
    "            filter_size = config[\"filter_sizes\"][block_no]\n",
    "            stride = config[\"conv_strides\"][block_no]\n",
    "            padding = config[\"conv_padding\"][block_no]\n",
    "            if padding == None:\n",
    "                padding = int((filter_size - 1)/2) if filter_size > 1 else 0\n",
    "            # Defining the block to add to conv_blocks #\n",
    "            block_add = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=filter_size, stride=stride, padding=padding),\n",
    "                nn.BatchNorm2d(num_features=out_channels) if config[\"batch_norm_conv\"] else nn.Identity(),\n",
    "                return_activation_function(activation=config[\"conv_activation\"][block_no]),\n",
    "                nn.MaxPool2d(kernel_size=config[\"max_pooling_kernel_size\"][block_no],stride=config[\"max_pooling_stride\"][block_no]) if config[\"max_pooling_stride\"][block_no] != None else nn.Identity(),\n",
    "                nn.Dropout(config[\"dropout_conv\"]) if config[\"dropout_conv\"]>0 else nn.Identity(),\n",
    "            )\n",
    "            # Appending the blocks to the total #\n",
    "            conv_blocks.append(block_add)\n",
    "\n",
    "        # Converting the list to a sequential module #\n",
    "        self.conv_blocks = nn.Sequential(*conv_blocks)\n",
    "\n",
    "        # Calculating the size of the output #\n",
    "        dummy_in = torch.randn(size=(1, config[\"input_channels\"],config[\"input_size\"][0], config[\"input_size\"][1]))\n",
    "        dummy_out = self.conv_blocks(dummy_in).flatten()\n",
    "        flat_size = len(dummy_out)\n",
    "\n",
    "        # building the fc blocks #\n",
    "        fc_blocks = []\n",
    "        for block_no in range(config[\"no_of_fc_layers\"]):\n",
    "            if block_no == 0:\n",
    "                in_channels = flat_size\n",
    "            else:\n",
    "                in_channels = config[\"fc_neurons\"][block_no-1]\n",
    "            out_channels = config[\"fc_neurons\"][block_no]\n",
    "            block_add = nn.Sequential(\n",
    "                nn.Linear(in_features=in_channels, out_features=out_channels),\n",
    "                nn.BatchNorm1d(out_channels) if config[\"batch_norm_fc\"] else nn.Identity(),\n",
    "                return_activation_function(activation=config[\"fc_activations\"][block_no]),\n",
    "                nn.Dropout(config[\"dropout_fc\"]) if config[\"dropout_fc\"]>0 else nn.Identity(),\n",
    "            )\n",
    "            # Appending to the fc final\n",
    "            fc_blocks.append(block_add)\n",
    "\n",
    "        # converting the list to a sequential module #\n",
    "        self.fc_layers = nn.Sequential(*fc_blocks)\n",
    "\n",
    "        # Output layer #\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(in_features=config[\"fc_neurons\"][-1], out_features=config[\"num_classes\"]),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_blocks(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1dce72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lightning_CNN(L.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Define the model\n",
    "        self.model = CNN_(config=config)\n",
    "\n",
    "        # Defining the loss and optimizers\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr = config[\"learning_rate\"])\n",
    "\n",
    "        # Defining the metrics\n",
    "        self.acc_metric = Accuracy(task=\"multiclass\", num_classes=config[\"num_classes\"], average=\"weighted\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_, target_ = batch\n",
    "        output_ = self(input_)\n",
    "        # Finding the loss to backprop #\n",
    "        loss = self.loss_fn(output_, target_)\n",
    "        # Logging the metrics #\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_, target_ = batch\n",
    "        output_ = self(input_)\n",
    "        # Finding the loss to backprop #\n",
    "        loss = self.loss_fn(output_, target_)\n",
    "\n",
    "        output_pred = torch.argmax(output_, dim=1) \n",
    "        acc = self.acc_metric(output_pred, target_)\n",
    "        # Logging the metrics #\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True, sync_dist=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, logger=True, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_, target_ = batch\n",
    "        output_ = self(input_)\n",
    "        # Finding the loss to backprop #\n",
    "        loss = self.loss_fn(output_, target_)\n",
    "        \n",
    "        output_pred = torch.argmax(output_, dim=1) \n",
    "        acc = self.acc_metric(output_pred, target_)\n",
    "        # Logging the metrics #\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True, sync_dist=True)\n",
    "        self.log(\"test_acc\", acc, prog_bar=True, logger=True, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e7c7635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing \n",
    "best_model_path = \"/home/joel/Pytorch_CUDA/checkpoints/best-checkpoint_2.ckpt\"\n",
    "model = Lightning_CNN.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f967460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels for stratified split\n",
    "labels = [sample[1] for sample in test_dataset.samples]\n",
    "# Stratified split #\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "_ , print_indices = train_test_split(\n",
    "    np.arange(len(labels)),\n",
    "    test_size=30,\n",
    "    stratify=labels,\n",
    ")\n",
    "\n",
    "# Create subsets\n",
    "print_dataset = Subset(test_dataset, print_indices)\n",
    "print_dataset.dataset.transform = data_transforms[\"orient_\"] \n",
    "\n",
    "batch_size = 30\n",
    "num_workers = 2 # Adaptive number of workers\n",
    "\n",
    "print_loader = DataLoader(\n",
    "    print_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    #pin_memory=True,\n",
    "    drop_last=True  # Helps with batch norm stability\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "631463d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/joel/Pytorch_CUDA/wandb/run-20250419_012516-jjb6h87i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/A2_DA6401_DL/Reporter/runs/jjb6h87i' target=\"_blank\">celestial-microwave-6</a></strong> to <a href='https://wandb.ai/A2_DA6401_DL/Reporter' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/A2_DA6401_DL/Reporter' target=\"_blank\">https://wandb.ai/A2_DA6401_DL/Reporter</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/A2_DA6401_DL/Reporter/runs/jjb6h87i' target=\"_blank\">https://wandb.ai/A2_DA6401_DL/Reporter/runs/jjb6h87i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor(30)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(config=None, entity=\"A2_DA6401_DL\", project=\"Reporter\")\n",
    "table = wandb.Table(columns=[\"Ground Truth\", \"Image 1\", \"Image 2\", \"Image 3\"])\n",
    "\n",
    "val = 0\n",
    "for batch in print_loader:\n",
    "    x,y = batch\n",
    "\n",
    "pred = torch.argmax(model(x), dim=1)\n",
    "\n",
    "for i in range(10):\n",
    "    true_label = print_dataset.dataset.classes[i]\n",
    "\n",
    "    table.add_data(\n",
    "        true_label,\n",
    "        wandb.Image(x[y==i][0], caption=print_dataset.dataset.classes[pred[y==i][0]]),\n",
    "        wandb.Image(x[y==i][1], caption=print_dataset.dataset.classes[pred[y==i][1]]),\n",
    "        wandb.Image(x[y==i][2], caption=print_dataset.dataset.classes[pred[y==i][2]]),\n",
    "    )\n",
    "    \n",
    "    val += torch.sum(pred == i)\n",
    "wandb.log({\"Grid of test predictions table\": table})\n",
    "\n",
    "val\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "949fbd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">celestial-microwave-6</strong> at: <a href='https://wandb.ai/A2_DA6401_DL/Reporter/runs/jjb6h87i' target=\"_blank\">https://wandb.ai/A2_DA6401_DL/Reporter/runs/jjb6h87i</a><br> View project at: <a href='https://wandb.ai/A2_DA6401_DL/Reporter' target=\"_blank\">https://wandb.ai/A2_DA6401_DL/Reporter</a><br>Synced 5 W&B file(s), 1 media file(s), 32 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250419_012516-jjb6h87i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53b90618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amphibia',\n",
       " 'Animalia',\n",
       " 'Arachnida',\n",
       " 'Aves',\n",
       " 'Fungi',\n",
       " 'Insecta',\n",
       " 'Mammalia',\n",
       " 'Mollusca',\n",
       " 'Plantae',\n",
       " 'Reptilia']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_dataset.dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dcf7b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 8, 2, 4, 3, 0, 3, 8, 5, 7, 7, 9, 4, 6, 9, 0, 2, 1, 7, 8, 8, 5, 9, 9,\n",
      "        1, 0, 2, 5, 4, 8])\n",
      "tensor([6, 9, 2, 8, 9, 7, 3, 0, 6, 7, 3, 0, 4, 3, 2, 9, 5, 1, 7, 8, 8, 5, 0, 6,\n",
      "        1, 2, 4, 5, 1, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = 0\n",
    "for batch in print_loader:\n",
    "    x, y = batch\n",
    "    input = x\n",
    "    \n",
    "    print(torch.argmax(model(input),dim=1))\n",
    "    print(y)\n",
    "\n",
    "    val += torch.sum(y == torch.argmax(model(input),dim=1))\n",
    "\n",
    "val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
