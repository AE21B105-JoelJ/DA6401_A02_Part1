{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    DA6401 - Assignment 02 (P1)\n",
    "        This notebook contains the source code written for this assignment which will be later transfered to a python scripy on successful passage of testing and checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries #\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as F\n",
    "import lightning as L\n",
    "from typing import List\n",
    "from lightning.pytorch import Trainer\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import precision_score\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mae21b105\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "wandb.login()\n",
    "# Initializing wandb logger #\n",
    "wandb_logger = WandbLogger(\n",
    "    entity=\"A2_DA6401_DL\",\n",
    "    project=\"Lightning_CNN\",       \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/joel/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=\"5ef7c4bbfa350a2ffd3c198cb9289f544e3a0910\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to give the activation function #\n",
    "def return_activation_function(activation : str = \"ReLU\"):\n",
    "    possible_activations = [\"ReLU\", \"Mish\", \"GELU\", \"SELU\", \"SiLU\", \"LeakyReLU\" ]\n",
    "    # Assertion to be made for the activations possible #\n",
    "    assert activation in possible_activations, f\"activation not in {possible_activations}\"\n",
    "\n",
    "    if activation == \"ReLU\":\n",
    "        return nn.ReLU()\n",
    "    elif activation == \"GELU\":\n",
    "        return nn.GELU()\n",
    "    elif activation == \"SiLU\":\n",
    "        return nn.SiLU()\n",
    "    elif activation == \"SELU\":\n",
    "        return nn.SELU()\n",
    "    elif activation == \"Mish\":\n",
    "        return nn.Mish()\n",
    "    else:\n",
    "        return nn.LeakyReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_(nn.Module):\n",
    "    def __init__(self, config = None):\n",
    "        super().__init__()\n",
    "        # Configuration to build the CNN #\n",
    "        self.config = config\n",
    "        \n",
    "        # Some assertions to be made #\n",
    "        assert config[\"no_of_conv_blocks\"]==len(config[\"no_of_filters\"]), \"The filter number do not match with number of conv layers\"\n",
    "        assert config[\"no_of_conv_blocks\"]==len(config[\"filter_sizes\"]), \"The filter sizes do not match with number of conv layers\"\n",
    "        assert config[\"no_of_conv_blocks\"]==len(config[\"conv_strides\"]), \"The strides do not match with number of conv layers\"\n",
    "        assert config[\"no_of_conv_blocks\"]==len(config[\"conv_padding\"]), \"The padding do not match with number of conv layers\"\n",
    "        assert config[\"no_of_conv_blocks\"]==len(config[\"max_pooling_stride\"]), \"The max pooling stride do not match with number of conv layers\"\n",
    "\n",
    "        # building the convolution blocks #\n",
    "        conv_blocks = []\n",
    "        for block_no in range(config[\"no_of_conv_blocks\"]):\n",
    "            # Getting the hyper-parameters from the config #\n",
    "            if block_no == 0:\n",
    "                in_channels = config[\"input_channels\"]\n",
    "            else:\n",
    "                in_channels = config[\"no_of_filters\"][block_no-1]\n",
    "            out_channels = config[\"no_of_filters\"][block_no]\n",
    "            filter_size = config[\"filter_sizes\"][block_no]\n",
    "            stride = config[\"conv_strides\"][block_no]\n",
    "            padding = config[\"conv_padding\"][block_no]\n",
    "            if padding == None:\n",
    "                padding = int((filter_size - 1)/2) if filter_size > 1 else 0\n",
    "            # Defining the block to add to conv_blocks #\n",
    "            block_add = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=filter_size, stride=stride, padding=padding),\n",
    "                nn.BatchNorm2d(num_features=out_channels) if config[\"batch_norm_conv\"] else nn.Identity(),\n",
    "                return_activation_function(activation=config[\"conv_activation\"][block_no]),\n",
    "                nn.MaxPool2d(kernel_size=config[\"max_pooling_kernel_size\"][block_no],stride=config[\"max_pooling_stride\"][block_no]) if config[\"max_pooling_stride\"][block_no] != None else nn.Identity(),\n",
    "                nn.Dropout(config[\"dropout_conv\"]) if config[\"dropout_conv\"]>0 else nn.Identity(),\n",
    "            )\n",
    "            # Appending the blocks to the total #\n",
    "            conv_blocks.append(block_add)\n",
    "\n",
    "        # Converting the list to a sequential module #\n",
    "        self.conv_blocks = nn.Sequential(*conv_blocks)\n",
    "\n",
    "        # Calculating the size of the output #\n",
    "        dummy_in = torch.randn(size=(1, config[\"input_channels\"],config[\"input_size\"][0], config[\"input_size\"][1]))\n",
    "        dummy_out = self.conv_blocks(dummy_in).flatten()\n",
    "        flat_size = len(dummy_out)\n",
    "\n",
    "        # building the fc blocks #\n",
    "        fc_blocks = []\n",
    "        for block_no in range(config[\"no_of_fc_layers\"]):\n",
    "            if block_no == 0:\n",
    "                in_channels = flat_size\n",
    "            else:\n",
    "                in_channels = config[\"fc_neurons\"][block_no-1]\n",
    "            out_channels = config[\"fc_neurons\"][block_no]\n",
    "            block_add = nn.Sequential(\n",
    "                nn.Linear(in_features=in_channels, out_features=out_channels),\n",
    "                nn.BatchNorm1d(out_channels) if config[\"batch_norm_fc\"] else nn.Identity(),\n",
    "                return_activation_function(activation=config[\"fc_activations\"][block_no]),\n",
    "                nn.Dropout(config[\"dropout_fc\"]) if config[\"dropout_fc\"]>0 else nn.Identity(),\n",
    "            )\n",
    "            # Appending to the fc final\n",
    "            fc_blocks.append(block_add)\n",
    "\n",
    "        # converting the list to a sequential module #\n",
    "        self.fc_layers = nn.Sequential(*fc_blocks)\n",
    "\n",
    "        # Output layer #\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(in_features=config[\"fc_neurons\"][-1], out_features=config[\"num_classes\"]),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_blocks(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lightning_CNN(L.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Define the model\n",
    "        self.model = CNN_(config=config)\n",
    "\n",
    "        # Defining the loss and optimizers\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr = config[\"learning_rate\"])\n",
    "\n",
    "        # Defining the metrics\n",
    "        self.acc_metric = Accuracy(task=\"multiclass\", num_classes=config[\"num_classes\"], average=\"weighted\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_, target_ = batch\n",
    "        output_ = self(input_)\n",
    "        # Finding the loss to backprop #\n",
    "        loss = self.loss_fn(output_, target_)\n",
    "        # Logging the metrics #\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_, target_ = batch\n",
    "        output_ = self(input_)\n",
    "        # Finding the loss to backprop #\n",
    "        loss = self.loss_fn(output_, target_)\n",
    "\n",
    "        output_pred = torch.argmax(output_, dim=1) \n",
    "        acc = self.acc_metric(output_pred, target_)\n",
    "        # Logging the metrics #\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True, sync_dist=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, logger=True, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_, target_ = batch\n",
    "        output_ = self(input_)\n",
    "        # Finding the loss to backprop #\n",
    "        loss = self.loss_fn(output_, target_)\n",
    "        \n",
    "        output_pred = torch.argmax(output_, dim=1) \n",
    "        acc = self.acc_metric(output_pred, target_)\n",
    "        # Logging the metrics #\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True, sync_dist=True)\n",
    "        self.log(\"test_acc\", acc, prog_bar=True, logger=True, sync_dist=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "config_best = {\n",
    "    \"no_of_conv_blocks\" : 5,\n",
    "    \"input_size\" : (256, 256),\n",
    "    \"input_channels\" : 3,\n",
    "    \"num_classes\" : 10,\n",
    "    \"no_of_filters\" : [128]*5,#[16, 32, 64, 128, 256],\n",
    "    \"conv_activation\" : [\"SiLU\"]*5,\n",
    "    \"filter_sizes\" : [5, 5, 5, 3, 3], # Filter sizes has to be odd number\n",
    "    \"conv_strides\" : [1, 1, 1, 1, 1],\n",
    "    \"conv_padding\" : [None, None, None, None, None], # Use None if you want no reduction in size of image (stride = 1)\n",
    "    \"max_pooling_kernel_size\" : [5, 5, 3, 3, 2],\n",
    "    \"max_pooling_stride\" : [3, 3, 3, 2, 2], # Use None if you dont want a max pooling between layers\n",
    "    \"batch_norm_conv\" : True,\n",
    "    \"dropout_conv\" : 0.2, # if dont need use 0\n",
    "    \"no_of_fc_layers\" : 1, # Ignore the output layer\n",
    "    \"fc_activations\" : [\"SELU\"], \n",
    "    \"fc_neurons\" : [512],\n",
    "    \"batch_norm_fc\" : True,\n",
    "    \"dropout_fc\" : 0.1, # if dont need use 0\n",
    "    \"learning_rate\" : 3e-4, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"no_of_conv_blocks\" : 5,\n",
    "    \"input_size\" : (256, 256),\n",
    "    \"input_channels\" : 3,\n",
    "    \"num_classes\" : 10,\n",
    "    \"no_of_filters\" : [128, 128, 128, 256, 256],\n",
    "    \"conv_activation\" : [\"GELU\"]*5,\n",
    "    \"filter_sizes\" : [5, 5, 5, 3, 3], # Filter sizes has to be odd number\n",
    "    \"conv_strides\" : [1, 1, 1, 1, 1],\n",
    "    \"conv_padding\" : [None, None, None, None, None], # Use None if you want no reduction in size of image (stride = 1)\n",
    "    \"max_pooling_kernel_size\" : [5, 5, 3, 2, 2],\n",
    "    \"max_pooling_stride\" : [3, 3, 3, 2, 2], # Use None if you dont want a max pooling between layers\n",
    "    \"batch_norm_conv\" : True,\n",
    "    \"dropout_conv\" : 0.1, # if dont need use 0\n",
    "    \"no_of_fc_layers\" : 1, # Ignore the output layer\n",
    "    \"fc_activations\" : [\"Mish\"], \n",
    "    \"fc_neurons\" : [512],\n",
    "    \"batch_norm_fc\" : True,\n",
    "    \"dropout_fc\" : 0.2, # if dont need use 0\n",
    "    \"learning_rate\" : 1e-4, \n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "model = Lightning_CNN(config=config)\n",
    "trainer = Trainer(max_epochs=10, accelerator=\"auto\")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to orient\n",
    "class OrientReshape:\n",
    "    def __init__(self, size = (256, 256)):\n",
    "        self.size = size\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        # rotate the image to landscape if potrait #\n",
    "        if img.height > img.width:\n",
    "            img = img.rotate(90, expand = True)\n",
    "        # Reshape to target dimension #\n",
    "        img = F.resize(img, size = self.size)\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augementation and transforms\n",
    "data_transforms = {\n",
    "    \"orient_\" : transforms.Compose([\n",
    "        OrientReshape(size=(256, 256)),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    \"train_\" : transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p = 0.2),\n",
    "        transforms.RandomVerticalFlip(p = 0.2),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.3),\n",
    "        transforms.GaussianBlur(kernel_size=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomErasing(p = 0.2, scale=(0.02, 0.075)),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Path to your dataset\n",
    "data_dir = os.path.join(os.path.abspath(\"\"), \"nature_12K/inaturalist_12K/train/\")  # Replace with your path\n",
    "\n",
    "# Create full dataset\n",
    "full_dataset = datasets.ImageFolder(root=data_dir, transform=data_transforms[\"orient_\"])\n",
    "\n",
    "# Get labels for stratified split\n",
    "labels = [sample[1] for sample in full_dataset.samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified split #\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_indices, val_indices = train_test_split(\n",
    "    np.arange(len(labels)),\n",
    "    test_size=0.2,\n",
    "    stratify=labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Create subsets\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "val_dataset = Subset(full_dataset, val_indices)\n",
    "train_dataset.dataset.transform = data_transforms['train_']\n",
    "val_dataset.dataset.transform = data_transforms[\"orient_\"] \n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 2 # Adaptive number of workers\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    #pin_memory=True,\n",
    "    drop_last=True  # Helps with batch norm stability\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    #pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel/Pytorch_CUDA/virt_env/lib/python3.12/site-packages/lightning/fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250418_195105-wyc5e0it</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/A2_DA6401_DL/Lightning_CNN/runs/wyc5e0it' target=\"_blank\">neat-dust-1184</a></strong> to <a href='https://wandb.ai/A2_DA6401_DL/Lightning_CNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/A2_DA6401_DL/Lightning_CNN' target=\"_blank\">https://wandb.ai/A2_DA6401_DL/Lightning_CNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/A2_DA6401_DL/Lightning_CNN/runs/wyc5e0it' target=\"_blank\">https://wandb.ai/A2_DA6401_DL/Lightning_CNN/runs/wyc5e0it</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel/Pytorch_CUDA/virt_env/lib/python3.12/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /home/joel/Pytorch_CUDA/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type               | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | model      | CNN_               | 2.2 M  | train\n",
      "1 | loss_fn    | CrossEntropyLoss   | 0      | train\n",
      "2 | acc_metric | MulticlassAccuracy | 0      | train\n",
      "----------------------------------------------------------\n",
      "2.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 M     Total params\n",
      "8.989     Total estimated model params size (MB)\n",
      "43        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c9e78da3564435789a860c82ee6d817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325981a646554b039def97ab862496e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efd864750074fcd9d783099a7a60655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e882e6a53c24bb99f839b5375b9ccb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba7eee0224a4fb5b9d664012bf9b20e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38df50986764f3a98adfb3a13fc5f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c16ef30f8eb432386aca65c435f4eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4ecc45584d485093e891a052aa6980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344cf16a28e448cfa684f5c7a35c6afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba874ba0413b4beea33e2d8dbf0a5263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1069140e23044f2cbecb6f8d1cfb0d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c47640c2524f78ba1597ecc9aa7cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f89a4db17e64b0796f26e88e755ad02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f3aa40ead24ad3ae80280154d29bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51be5944355d4ddc969de5f415a2ed65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18de1cb66674dbfa0d98fc1facce688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b3c8030fd64c01a40739e2e7a01679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1044e9bafbc9473db194fa8829b39fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe1754c6d9c402f871dd446f683f5c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2201be7d2eac490f888475147017491c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2b85f965ae4f30877011358f8e203b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037c9dec34834c3ba11ab61a99920020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7828fa70962f4480b87d75b03e1637c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32a09ceaac34ac4916ad78584e704b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f045836ca24f6d8d9d8c7b8a85e69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8c354ceb9c49b8bdef1d57328588e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e933127abe37441285fa483a935b6e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c8b33a55f04e14bf55b01a11f3efdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86ae0e65d7c44698f394b3cb0aacff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff9b74e111e430981fc9f48769f5775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e069d6a941f426caa3d4ed8d166c874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65897b4ff46f4c008c05c2e64a6913d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ed5029fd3c483196bd14ca09891027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4eb7a7dbc5644368f333ecc5c81fe2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "036c517e348b4a46b395e0cf99bbbbf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call backs\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "early_stopping = EarlyStopping('val_acc', patience=10, mode=\"max\")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_acc\",\n",
    "    dirpath=\"checkpoints/\",     # Folder to save\n",
    "    filename=\"best-checkpoint_2\", # File name\n",
    "    save_top_k=1,\n",
    "    mode=\"max\"                  # Save only when val_loss is minimized\n",
    ")\n",
    "\n",
    "model = Lightning_CNN(config=config)\n",
    "trainer = Trainer(max_epochs=50, precision=16, accelerator=\"auto\", logger=wandb_logger, callbacks=[early_stopping, checkpoint_callback])\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>███▇█▆▇▆▄▅▅▄▄▄▅▄▄▃▃▄▃▄▄▂▅▂▂▂▁▂▂▃▂▂▃▂▃▃▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>val_acc</td><td>▁▃▃▄▅▅▆▆▆▆▆▇▇▇▆▇▇▇▇█▆▇█▆▇▇█▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▆▆▅▄▄▃▃▃▃▃▂▂▂▃▂▂▂▂▁▃▂▁▂▂▂▁▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>32</td></tr><tr><td>train_loss_epoch</td><td>1.66075</td></tr><tr><td>train_loss_step</td><td>1.79858</td></tr><tr><td>trainer/global_step</td><td>8216</td></tr><tr><td>val_acc</td><td>0.429</td></tr><tr><td>val_loss</td><td>2.03048</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neat-dust-1184</strong> at: <a href='https://wandb.ai/A2_DA6401_DL/Lightning_CNN/runs/wyc5e0it' target=\"_blank\">https://wandb.ai/A2_DA6401_DL/Lightning_CNN/runs/wyc5e0it</a><br> View project at: <a href='https://wandb.ai/A2_DA6401_DL/Lightning_CNN' target=\"_blank\">https://wandb.ai/A2_DA6401_DL/Lightning_CNN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250418_195105-wyc5e0it/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "# Path to your dataset\n",
    "data_dir = os.path.join(os.path.abspath(\"\"), \"nature_12K/inaturalist_12K/val/\")  # Replace with your path\n",
    "\n",
    "# Create full dataset\n",
    "test_dataset = datasets.ImageFolder(root=data_dir, transform=data_transforms[\"orient_\"])\n",
    "\n",
    "test_dataset.transform = data_transforms[\"orient_\"] \n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 2 # Adaptive number of workers\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    #pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing \n",
    "best_model_path = checkpoint_callback.best_model_path\n",
    "model = Lightning_CNN.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d517f6dcec2f4078b94d2e29e486c9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joel/Pytorch_CUDA/virt_env/lib/python3.12/site-packages/lightning/pytorch/core/module.py:512: You called `self.log('test_loss', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n",
      "/home/joel/Pytorch_CUDA/virt_env/lib/python3.12/site-packages/lightning/pytorch/core/module.py:512: You called `self.log('test_acc', ..., logger=True)` but have no logger configured. You can enable one by doing `Trainer(logger=ALogger(...))`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.45750001072883606    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     2.00131893157959      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.45750001072883606   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    2.00131893157959     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Disable wandb or other loggers during inference to avoid usage errors\n",
    "trainer = Trainer(logger=False)\n",
    "\n",
    "# Run prediction\n",
    "predictions = trainer.test(model=model, dataloaders=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virt_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
